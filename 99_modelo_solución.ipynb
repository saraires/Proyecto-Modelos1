{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saraires/Proyecto-Modelos1/blob/main/99_modelo_soluci%C3%B3n.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NL1bPJwDf8c-"
      },
      "source": [
        "# Extrayendo Información desde Kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQgGS7Jug23U"
      },
      "source": [
        "# **99 - modelo solución**\n",
        "### Santiago Palacio Cárdenas\n",
        "### Sarai Restrepo Rodríguez\n",
        "### Natalia Bernal Gutiérrez"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfjDv52UhVwu"
      },
      "source": [
        "En este notebook desarrollamos un modelo de clasificación supervisada para predecir el rendimiento global de los estudiantes en las pruebas Saber Pro, utilizando técnicas avanzadas de ingeniería de características y un modelo CatBoost optimizado para datos categóricos. A lo largo del flujo, realizamos el procesamiento del conjunto de entrenamiento, entrenamos el modelo en fase de validación para evaluar su desempeño y finalmente construimos un modelo definitivo con todos los datos disponibles para generar el archivo de envío requerido por Kaggle. Este notebook documenta de manera clara cada paso del proceso para garantizar reproducibilidad, trazabilidad y comprensión del pipeline completo.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpzc75qshfpY"
      },
      "source": [
        "# **1. Extrayendo Información desde Kaggle**\n",
        "\n",
        "En esta sección descargamos los archivos oficiales de la competencia directamente desde Kaggle usando la interfaz de línea de comandos, lo cual nos permite obtener las versiones más recientes del conjunto de entrenamiento, prueba y ejemplos de envío. Esta descarga garantiza que trabajemos con los datos proporcionados por la competencia sin modificaciones locales y mantiene la coherencia entre el entorno de trabajo y la plataforma de evaluación. Además, dejar explícito el comando de extracción permite que cualquier persona que abra el notebook pueda replicar el proceso fácilmente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lO_jkzozuVuI",
        "outputId": "f4e13356-ca01-4c85-bfe6-605ec40fdd41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "kaggle.json configurado en C:\\Users\\sarai\\.kaggle\n",
            "Descargando archivos de la competencia a: C:\\Users\\sarai\\Downloads\n",
            "Downloading udea-ai-4-eng-20252-pruebas-saber-pro-colombia.zip to C:\\Users\\sarai\\Downloads\n",
            "Downloading udea-ai-4-eng-20252-pruebas-saber-pro-colombia.zip to C:\\Users\\sarai\\Downloads\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 29.9M/29.9M [00:03<00:00, 9.19MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Descarga completada.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Descargar datos desde Kaggle (opcional, requiere kaggle.json)\n",
        "import os, shutil\n",
        "from pathlib import Path\n",
        "\n",
        "def setup_kaggle_config():\n",
        "    # Busca kaggle.json en carpeta actual o Descargas y lo copia a ~/.kaggle\n",
        "    candidates = [\n",
        "        Path('kaggle.json'),\n",
        "        Path.home() / 'Downloads' / 'kaggle.json',\n",
        "    ]\n",
        "    dest_dir = Path.home() / '.kaggle'\n",
        "    dest_dir.mkdir(exist_ok=True)\n",
        "    for c in candidates:\n",
        "        if c.exists():\n",
        "            shutil.copy2(str(c), str(dest_dir / 'kaggle.json'))\n",
        "            print(f\"kaggle.json configurado en {dest_dir}\")\n",
        "            return True\n",
        "    print(\"No se encontró kaggle.json. Coloca tu token en la carpeta del notebook o en Descargas.\")\n",
        "    return False\n",
        "\n",
        "def kaggle_download():\n",
        "    try:\n",
        "        from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "    except Exception as e:\n",
        "        print(\"Kaggle API no disponible. Asegúrate de haber instalado 'kaggle'.\")\n",
        "        return False\n",
        "    if not setup_kaggle_config():\n",
        "        return False\n",
        "    try:\n",
        "        api = KaggleApi(); api.authenticate()\n",
        "        target = Path.home() / 'Downloads'\n",
        "        comp = 'udea-ai-4-eng-20252-pruebas-saber-pro-colombia'\n",
        "        print(f\"Descargando archivos de la competencia a: {target}\")\n",
        "        api.competition_download_files(comp, path=str(target), quiet=False)\n",
        "        print(\"Descarga completada.\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Fallo en descarga Kaggle: {e}\")\n",
        "        return False\n",
        "\n",
        "_ = kaggle_download()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTOVjC5BuW4o",
        "outputId": "acf672ec-1e09-4e65-bb73-6f73f435502b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extraído: .\\udea-ai-4-eng-20252-pruebas-saber-pro-colombia-publicleaderboard-2025-11-27T16_03_07.zip -> .\n",
            "Extraído: .\\udea-ai-4-eng-20252-pruebas-saber-pro-colombia.zip -> .\n",
            "Extraído: C:\\Users\\sarai\\Downloads\\udea-ai-4-eng-20252-pruebas-saber-pro-colombia-publicleaderboard-2025-11-27T16_03_07.zip -> C:\\Users\\sarai\\Downloads\n",
            "Extraído: .\\udea-ai-4-eng-20252-pruebas-saber-pro-colombia.zip -> .\n",
            "Extraído: C:\\Users\\sarai\\Downloads\\udea-ai-4-eng-20252-pruebas-saber-pro-colombia-publicleaderboard-2025-11-27T16_03_07.zip -> C:\\Users\\sarai\\Downloads\n",
            "Extraído: C:\\Users\\sarai\\Downloads\\udea-ai-4-eng-20252-pruebas-saber-pro-colombia.zip -> C:\\Users\\sarai\\Downloads\n",
            "Extraído: C:\\Users\\sarai\\Downloads\\udea-ai-4-eng-20252-pruebas-saber-pro-colombia.zip -> C:\\Users\\sarai\\Downloads\n"
          ]
        }
      ],
      "source": [
        "# Descomprimir archivos descargados de Kaggle de forma portable\n",
        "import os, glob, zipfile\n",
        "\n",
        "def extract_kaggle_zip():\n",
        "    candidates = []\n",
        "    downloads = os.path.join(os.path.expanduser('~'), 'Downloads')\n",
        "    candidates += glob.glob(os.path.join('.', 'udea*pruebas*colombia*.zip'))\n",
        "    candidates += glob.glob(os.path.join(downloads, 'udea*pruebas*colombia*.zip'))\n",
        "    for z in candidates:\n",
        "        try:\n",
        "            target_dir = os.path.dirname(z)\n",
        "            with zipfile.ZipFile(z, 'r') as zf:\n",
        "                zf.extractall(target_dir)\n",
        "            print(f\"Extraído: {z} -> {target_dir}\")\n",
        "        except Exception as e:\n",
        "            print(f\"No se pudo extraer {z}: {e}\")\n",
        "\n",
        "extract_kaggle_zip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqxyGENmgKDt"
      },
      "source": [
        "# **2. Importaciones e instalaciones necesarias**\n",
        "\n",
        "En esta sección instalamos y cargamos todas las librerías esenciales que utilizaremos a lo largo del desarrollo del modelo. Primero instalamos CatBoost, un algoritmo altamente eficiente para manejar grandes cantidades de variables categóricas y adecuado para problemas de clasificación multiclase como el rendimiento Saber Pro. Luego importamos herramientas de manejo de datos como pandas y numpy, junto con funciones de scikit-learn para realizar particiones, métricas de evaluación y manejo de pools de datos. Finalmente, cargamos librerías de visualización como matplotlib y seaborn, que nos permitirán analizar el comportamiento del modelo a través de gráficas como la matriz de confusión y las curvas de aprendizaje. Estas importaciones preparan el entorno completo para ejecutar todo el pipeline de principio a fin.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjgX6MUPBXFk",
        "outputId": "62b92b33-1a50-454a-eebc-57f659b441ae"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.2 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install -q scikit-learn seaborn matplotlib kaggle\n",
        "try:\n",
        "    import catboost\n",
        "    from catboost import CatBoostClassifier, Pool\n",
        "    HAS_CATBOOST = True\n",
        "except Exception:\n",
        "    HAS_CATBOOST = False\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLKcA7gags0O"
      },
      "source": [
        "# **3. Definición de la Clase del Modelo**\n",
        "\n",
        "En esta sección definimos la clase encargada de todo el proceso de construcción del modelo de predicción, incluyendo el preprocesamiento, la ingeniería de características, el entrenamiento y la generación de predicciones finales. Esta clase agrupa de manera modular y organizada todas las funciones necesarias para limpiar los datos, transformar variables categóricas, realizar codificación basada en el rendimiento histórico, crear nuevas características socioeconómicas y educativas, entrenar el modelo CatBoost y producir los resultados en el formato requerido por Kaggle. Centralizar el pipeline dentro de una clase permite mantener el código más limpio, reutilizable y fácil de depurar, además de facilitar la ejecución tanto del modelo de validación como del modelo final entrenado con todos los datos disponibles.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzdcthT2JlB2"
      },
      "outputs": [],
      "source": [
        "class StudentPerformanceClassifier:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.model = None\n",
        "        self.feature_importance = None\n",
        "        self.target_encodings = {}\n",
        "        self.training_columns = []\n",
        "        self.categorical_features = []\n",
        "        self.evals_result = None\n",
        "        self.df_train = None\n",
        "        self.class_weights = None\n",
        "\n",
        "    def _encode_non_numeric(self, df):\n",
        "        for col in df.columns:\n",
        "            if not pd.api.types.is_numeric_dtype(df[col]):\n",
        "                df[col] = pd.Categorical(df[col]).codes\n",
        "        return df\n",
        "\n",
        "    # ... other methods ...\n",
        "\n",
        "    def _preprocess_common(self, df):\n",
        "        cols_to_drop = [\n",
        "            \"ID\",\n",
        "            \"INDICADOR_1\",\n",
        "            \"INDICADOR_2\",\n",
        "            \"INDICADOR_3\",\n",
        "            \"INDICADOR_4\",\n",
        "            \"F_TIENEINTERNET.1\"\n",
        "        ]\n",
        "\n",
        "        X = df.drop(columns=[c for c in cols_to_drop if c in df.columns], errors=\"ignore\").copy()\n",
        "\n",
        "        y = None\n",
        "        if \"RENDIMIENTO_GLOBAL\" in X.columns:\n",
        "            y = X.pop(\"RENDIMIENTO_GLOBAL\")\n",
        "\n",
        "        for col in X.select_dtypes(include=[\"object\"]).columns:\n",
        "            X[col] = X[col].fillna(\"No reporta\")\n",
        "\n",
        "        if \"PERIODO_ACADEMICO\" in X.columns:\n",
        "            X[\"PERIODO_ACADEMICO\"] = X[\"PERIODO_ACADEMICO\"].astype(str)\n",
        "\n",
        "        X = self.create_education_features(X)\n",
        "        X = self.create_economic_features(X)\n",
        "\n",
        "        if not ('HAS_CATBOOST' in globals() and HAS_CATBOOST):\n",
        "            X = self._encode_non_numeric(X)\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def preprocess_data(self, data, validation_mode=True):\n",
        "        X, y = self._preprocess_common(data)\n",
        "\n",
        "        class SklearnPool:\n",
        "            def __init__(self, X, y, cat_features=None):\n",
        "                self._X = X\n",
        "                self._y = y\n",
        "                self._cat = cat_features or []\n",
        "            def get_features(self):\n",
        "                return self._X\n",
        "            def get_label(self):\n",
        "                return np.array(self._y) if y is not None else None\n",
        "\n",
        "        if validation_mode:\n",
        "            print(\"Modo: Validación (dividiendo datos)\")\n",
        "\n",
        "            X_train, X_test, y_train, y_test = train_test_split(\n",
        "                X, y, test_size=0.2, random_state=42, stratify=y\n",
        "            )\n",
        "\n",
        "            train_target_df = X_train.copy()\n",
        "            train_target_df[\"RENDIMIENTO_GLOBAL\"] = y_train\n",
        "\n",
        "            X_train = self.create_location_program_features(X_train, train_target_df)\n",
        "            X_test = self.create_location_program_features(X_test)\n",
        "\n",
        "            if not ('HAS_CATBOOST' in globals() and HAS_CATBOOST):\n",
        "                X_train = self._encode_non_numeric(X_train)\n",
        "                X_test = self._encode_non_numeric(X_test)\n",
        "\n",
        "            self.df_train = X_train.copy()\n",
        "            self.training_columns = X_train.columns\n",
        "            self.categorical_features = X_train.select_dtypes(include=[\"object\"]).columns.tolist()\n",
        "\n",
        "            class_counts = y_train.value_counts()\n",
        "            total = class_counts.sum()\n",
        "            weights = {cls: total / (len(class_counts) * cnt) for cls, cnt in class_counts.items()}\n",
        "            self.class_weights = weights\n",
        "\n",
        "            if 'HAS_CATBOOST' in globals() and HAS_CATBOOST:\n",
        "                return (\n",
        "                    Pool(X_train, y_train, cat_features=self.categorical_features)\n",
        ",\n",
        "                    Pool(X_test, y_test, cat_features=self.categorical_features)\n",
        "                )\n",
        "            else:\n",
        "                return (\n",
        "                    SklearnPool(X_train, y_train, self.categorical_features)\n",
        ",\n",
        "                    SklearnPool(X_test, y_test, self.categorical_features)\n",
        "                )\n",
        "\n",
        "        else:\n",
        "            print(\"Modo: Entrenamiento final\")\n",
        "\n",
        "            df_target = pd.concat([X, y.rename(\"RENDIMIENTO_GLOBAL\")], axis=1)\n",
        "            X = self.create_location_program_features(X, df_target)\n",
        "\n",
        "            if not ('HAS_CATBOOST' in globals() and HAS_CATBOOST):\n",
        "                X = self._encode_non_numeric(X)\n",
        "\n",
        "            self.df_train = X.copy()\n",
        "            self.training_columns = X.columns\n",
        "            self.categorical_features = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
        "\n",
        "            class_counts = y.value_counts()\n",
        "            total = class_counts.sum()\n",
        "            self.class_weights = {cls: total / (len(class_counts) * cnt) for cls, cnt in class_counts.items()}\n",
        "\n",
        "            if 'HAS_CATBOOST' in globals() and HAS_CATBOOST:\n",
        "                return Pool(X, y, cat_features=self.categorical_features)\n",
        "            else:\n",
        "                return SklearnPool(X, y, self.categorical_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmwk43uahNL_"
      },
      "source": [
        "# **4. Uso de la Clase**\n",
        "\n",
        "En esta sección utilizamos la clase previamente definida para ejecutar el flujo completo de validación del modelo, comenzando por cargar el dataset de entrenamiento, aplicar todo el proceso de preprocesamiento y generar los conjuntos de datos internos que CatBoost requiere (train_pool y test_pool). Luego se instancia el clasificador, se divide la información en datos de entrenamiento y validación y se entrena el modelo activando técnicas como early stopping gracias al uso del eval_pool. Este paso nos permite verificar el comportamiento real del modelo antes de entrenar la versión final, analizar su rendimiento, revisar las curvas de aprendizaje y validar que todos los componentes del pipeline —como la ingeniería de características, las codificaciones y los parámetros del modelo— están funcionando correctamente antes de continuar con el entrenamiento final y la creación del archivo de envío para Kaggle.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZkPk0SB-dPI",
        "outputId": "83a7afc7-26f5-4605-c728-1009658a3a2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cargando train.csv desde: .\\train.csv\n"
          ]
        }
      ],
      "source": [
        "# Cargar datos con búsqueda robusta de rutas\n",
        "import os, glob, zipfile\n",
        "\n",
        "def find_file(filename):\n",
        "    candidates = [\n",
        "        '.',\n",
        "        os.getcwd(),\n",
        "        os.path.expanduser('~'),\n",
        "        os.path.join(os.path.expanduser('~'), 'Downloads'),\n",
        "        os.path.dirname(os.path.abspath('.')),\n",
        "    ]\n",
        "    for d in candidates:\n",
        "        p = os.path.join(d, filename)\n",
        "        if os.path.exists(p):\n",
        "            return p\n",
        "    # Búsqueda recursiva en Descargas (acotada)\n",
        "    dl = os.path.join(os.path.expanduser('~'), 'Downloads')\n",
        "    try:\n",
        "        matches = glob.glob(os.path.join(dl, '**', filename), recursive=True)\n",
        "        if matches:\n",
        "            return matches[0]\n",
        "    except Exception:\n",
        "        pass\n",
        "    return None\n",
        "\n",
        "# Intentar descomprimir si hay zip de Kaggle\n",
        "def maybe_unzip_kaggle_zip():\n",
        "    dl = os.path.join(os.path.expanduser('~'), 'Downloads')\n",
        "    zips = glob.glob(os.path.join(dl, 'udea*pruebas**.zip')) + glob.glob('udea*pruebas**.zip')\n",
        "    for z in zips:\n",
        "        try:\n",
        "            with zipfile.ZipFile(z, 'r') as zf:\n",
        "                zf.extractall(os.path.dirname(z))\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "TRAIN_PATH = os.environ.get('SP_TRAIN_PATH') or find_file('train.csv')\n",
        "TEST_PATH = os.environ.get('SP_TEST_PATH') or find_file('test.csv')\n",
        "\n",
        "if TRAIN_PATH is None or TEST_PATH is None:\n",
        "    maybe_unzip_kaggle_zip()\n",
        "    TRAIN_PATH = TRAIN_PATH or find_file('train.csv')\n",
        "    TEST_PATH = TEST_PATH or find_file('test.csv')\n",
        "\n",
        "if TRAIN_PATH is None:\n",
        "    raise FileNotFoundError(\"No se encontró 'train.csv'. Coloca el archivo en la misma carpeta del notebook o en Descargas.\")\n",
        "\n",
        "print(f\"Cargando train.csv desde: {TRAIN_PATH}\")\n",
        "data = pd.read_csv(TRAIN_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPv5aCJyurXQ",
        "outputId": "dce29914-5a1a-4682-d238-39b0110c3d4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Iniciando Fase de Validación ===\n"
          ]
        }
      ],
      "source": [
        "# Instanciar el clasificador\n",
        "print(\"=== Iniciando Fase de Validación ===\")\n",
        "classifier = StudentPerformanceClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jb2osikG3TUr",
        "outputId": "c90dff28-e64a-461c-e258-875fe5109ce0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modo: Validación (dividiendo datos)\n"
          ]
        }
      ],
      "source": [
        "# Preprocesamiento en modo validación\n",
        "train_pool, test_pool = classifier.preprocess_data(\n",
        "    data,\n",
        "    validation_mode=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urOiLanC3VLf",
        "outputId": "1ccb600a-96ae-4820-a1a2-8879ed847700"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Entrenando modelo de validación... ===\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "could not convert string to float: 'CONTADURIA PUBLICA'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_26312\\1244795992.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Entrenamiento del modelo con eval_pool para activar early stopping\u001b[39;00m\n\u001b[32m      2\u001b[39m print(\u001b[33m\"\\n=== Entrenando modelo de validación... ===\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m classifier.train_model(train_pool, eval_pool=test_pool)\n\u001b[32m      4\u001b[39m print(\u001b[33m\"=== Entrenamiento completado ===\"\u001b[39m)\n",
            "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_26312\\3932370770.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, train_pool, eval_pool)\u001b[39m\n\u001b[32m    298\u001b[39m                 class_weight=\u001b[33m'balanced_subsample'\u001b[39m,\n\u001b[32m    299\u001b[39m                 max_features=\u001b[33m'sqrt'\u001b[39m,\n\u001b[32m    300\u001b[39m                 min_samples_leaf=\u001b[32m2\u001b[39m\n\u001b[32m    301\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m302\u001b[39m             self.model.fit(X, y)\n\u001b[32m    303\u001b[39m             self.evals_result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    304\u001b[39m             self.feature_importance = getattr(self.model, \u001b[33m'feature_importances_'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
            "\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\sklearn\\base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1361\u001b[39m                 skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m                     prefer_skip_nested_validation \u001b[38;5;28;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m                 )\n\u001b[32m   1364\u001b[39m             ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
            "\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    355\u001b[39m         \u001b[38;5;66;03m# Validate or convert input data\u001b[39;00m\n\u001b[32m    356\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[32m    357\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\u001b[33m\"sparse multilabel-indicator for y is not supported.\"\u001b[39m)\n\u001b[32m    358\u001b[39m \n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m         X, y = validate_data(\n\u001b[32m    360\u001b[39m             self,\n\u001b[32m    361\u001b[39m             X,\n\u001b[32m    362\u001b[39m             y,\n",
            "\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\sklearn\\utils\\validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2967\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"estimator\"\u001b[39m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m check_y_params:\n\u001b[32m   2968\u001b[39m                 check_y_params = {**default_check_params, **check_y_params}\n\u001b[32m   2969\u001b[39m             y = check_array(y, input_name=\u001b[33m\"y\"\u001b[39m, **check_y_params)\n\u001b[32m   2970\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2971\u001b[39m             X, y = check_X_y(X, y, **check_params)\n\u001b[32m   2972\u001b[39m         out = X, y\n\u001b[32m   2973\u001b[39m \n\u001b[32m   2974\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m no_val_X \u001b[38;5;28;01mand\u001b[39;00m check_params.get(\u001b[33m\"ensure_2d\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
            "\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\sklearn\\utils\\validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[39m\n\u001b[32m   1364\u001b[39m         )\n\u001b[32m   1365\u001b[39m \n\u001b[32m   1366\u001b[39m     ensure_all_finite = _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n\u001b[32m   1367\u001b[39m \n\u001b[32m-> \u001b[39m\u001b[32m1368\u001b[39m     X = check_array(\n\u001b[32m   1369\u001b[39m         X,\n\u001b[32m   1370\u001b[39m         accept_sparse=accept_sparse,\n\u001b[32m   1371\u001b[39m         accept_large_sparse=accept_large_sparse,\n",
            "\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\sklearn\\utils\\validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1050\u001b[39m                         )\n\u001b[32m   1051\u001b[39m                     array = xp.astype(array, dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1052\u001b[39m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1053\u001b[39m                     array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n\u001b[32m-> \u001b[39m\u001b[32m1054\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[32m   1055\u001b[39m                 raise ValueError(\n\u001b[32m   1056\u001b[39m                     \u001b[33m\"Complex data not supported\\n{}\\n\"\u001b[39m.format(array)\n\u001b[32m   1057\u001b[39m                 ) \u001b[38;5;28;01mfrom\u001b[39;00m complex_warning\n",
            "\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\sklearn\\utils\\_array_api.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, dtype, order, copy, xp, device)\u001b[39m\n\u001b[32m    753\u001b[39m         \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[32m    754\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    755\u001b[39m             array = numpy.array(array, order=order, dtype=dtype)\n\u001b[32m    756\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m             array = numpy.asarray(array, order=order, dtype=dtype)\n\u001b[32m    758\u001b[39m \n\u001b[32m    759\u001b[39m         \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[32m    760\u001b[39m         \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n",
            "\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, dtype, copy)\u001b[39m\n\u001b[32m   2167\u001b[39m             )\n\u001b[32m   2168\u001b[39m         values = self._values\n\u001b[32m   2169\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2170\u001b[39m             \u001b[38;5;66;03m# Note: branch avoids `copy=None` for NumPy 1.x support\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2171\u001b[39m             arr = np.asarray(values, dtype=dtype)\n\u001b[32m   2172\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2173\u001b[39m             arr = np.array(values, dtype=dtype, copy=copy)\n\u001b[32m   2174\u001b[39m \n",
            "\u001b[31mValueError\u001b[39m: could not convert string to float: 'CONTADURIA PUBLICA'"
          ]
        }
      ],
      "source": [
        "# Entrenamiento del modelo con eval_pool para activar early stopping\n",
        "print(\"\\n=== Entrenando modelo de validación... ===\")\n",
        "classifier.train_model(train_pool, eval_pool=test_pool)\n",
        "print(\"=== Entrenamiento completado ===\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OcmC_s-y5n9m"
      },
      "outputs": [],
      "source": [
        "# Graficar curvas de aprendizaje\n",
        "print(\"\\n=== Curvas de aprendizaje ===\")\n",
        "classifier.plot_learning_curve()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJC_pfVmihwh"
      },
      "outputs": [],
      "source": [
        "# Ver la forma final de los datos preprocesados\n",
        "classifier.df_train.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVfmJ9fGhb7f"
      },
      "source": [
        "# **5. Evaluación del Modelo en Fase de Validación**\n",
        "\n",
        "En esta sección evaluamos el rendimiento del modelo entrenado durante la fase de validación, utilizando exclusivamente el conjunto de datos reservado como test interno para medir la capacidad real de generalización. A partir de las predicciones generadas por el modelo, calculamos métricas clave como precisión, recall, f1-score y accuracy, lo que nos permite identificar el comportamiento del clasificador en cada una de las clases objetivo del rendimiento académico. Asimismo, construimos y visualizamos la matriz de confusión para detectar patrones de error, especialmente la forma en que el modelo distingue entre categorías como medio-alto y medio-bajo, que suelen presentar mayor confusión. Esta evaluación es fundamental para validar que la ingeniería de características, las codificaciones y los parámetros del modelo están funcionando correctamente antes de proceder al entrenamiento final con todos los datos disponibles.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8ADL8GdheVH"
      },
      "outputs": [],
      "source": [
        "report, cm = classifier.evaluate_model(test_pool)\n",
        "\n",
        "# Nombres reales de las clases\n",
        "label_names = ['bajo', 'medio-bajo', 'medio-alto', 'alto']\n",
        "\n",
        "print(\"\\n=== Reporte de Clasificación ===\")\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1qgAB2L4n6q"
      },
      "outputs": [],
      "source": [
        "print(\"\\n=== Matriz de Confusión ===\")\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "sns.heatmap(\n",
        "    cm,\n",
        "    annot=True,\n",
        "    fmt=\"d\",\n",
        "    cmap=\"Blues\",\n",
        "    xticklabels=label_names,\n",
        "    yticklabels=label_names\n",
        ")\n",
        "\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPB1Y5H9hg2X"
      },
      "source": [
        "# **6. Entrenamiento Final y Generación de Predicciones para Kaggle**\n",
        "\n",
        "En esta etapa realizamos el entrenamiento final del modelo utilizando el 100% de los datos disponibles en el archivo *train.csv*, sin dividir en validación, con el fin de maximizar la capacidad de aprendizaje del clasificador antes de generar las predicciones oficiales para el reto de Kaggle. Primero se preprocesa nuevamente todo el dataset completo, aplicando la misma ingeniería de características, codificaciones y transformaciones que se emplearon en la fase de validación, garantizando consistencia entre el modelo final y las pruebas anteriores. Una vez entrenado el modelo final, cargamos el archivo *test.csv*, aplicamos el preprocesamiento correspondiente y generamos las etiquetas de rendimiento para cada estudiante, produciendo finalmente el archivo *my_submission.csv* en el formato exacto exigido por la plataforma. Este archivo será el que posteriormente se enviará a Kaggle para obtener la puntuación del modelo en los datos ocultos del concurso."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBf7ZC2T3vqT"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\\n--- Iniciando Fase de Entrenamiento Final ---\")\n",
        "\n",
        "# Cargar test de Kaggle\n",
        "X_test = pd.read_csv('test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJfAwJo34zyy"
      },
      "outputs": [],
      "source": [
        "# Crear nuevo clasificador limpio\n",
        "final_classifier = StudentPerformanceClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sa5eDzVZ41bb"
      },
      "outputs": [],
      "source": [
        "# Preprocesar TODOS los datos de entrenamiento (sin validación)\n",
        "final_train_pool = final_classifier.preprocess_data(\n",
        "    data,\n",
        "    validation_mode=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpcC1ymw42x9"
      },
      "outputs": [],
      "source": [
        "# Entrenar el modelo final\n",
        "print(\"\\n--- Entrenando modelo final... ---\")\n",
        "final_classifier.train_model(final_train_pool)\n",
        "print(\"--- Entrenamiento final completado. ---\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Tq5XA7oKGHv"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# GENERAR Y GUARDAR PREDICCIONES PARA KAGGLE\n",
        "# ============================================================\n",
        "\n",
        "results = final_classifier.save_predictions(\n",
        "    X_test,\n",
        "    'my_submission.csv'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ow5PmoCZJ2ma"
      },
      "outputs": [],
      "source": [
        "submission = final_classifier.save_predictions(X_test, \"my_submission.csv\")\n",
        "submission.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSSEaMugNoQU"
      },
      "outputs": [],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bc672780"
      },
      "outputs": [],
      "source": [
        "print(\"\\n=== Conteo de clases reales (train) ===\")\n",
        "print(data['RENDIMIENTO_GLOBAL'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27wJajj3hngv"
      },
      "source": [
        "# **7. Envío del archivo a Kaggle**\n",
        "\n",
        "En esta sección realizamos el envío oficial del archivo *my_submission.csv* a Kaggle. Una vez entrenado el modelo final y generadas las predicciones, usamos la interfaz de línea de comandos de Kaggle para cargar el archivo en la competencia y obtener la puntuación correspondiente en los datos ocultos del reto. Este paso completa el pipeline, permitiendo evaluar el desempeño real del modelo en el entorno competitivo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpRe_3ikf_eU"
      },
      "outputs": [],
      "source": [
        "!head my_submission.csv\n",
        "!kaggle competitions list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CaIRv8EvgDjv"
      },
      "outputs": [],
      "source": [
        "!kaggle competitions submit -c udea-ai-4-eng-20252-pruebas-saber-pro-colombia -f my_submission.csv -m \"versión final catboost\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}