{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saraires/Proyecto-Modelos1/blob/main/99_modelo_soluci%C3%B3n.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQgGS7Jug23U"
      },
      "source": [
        "# **99 - modelo solución**\n",
        "### Santiago Palacio Cárdenas\n",
        "### Sarai Restrepo Rodríguez\n",
        "### Natalia Bernal Gutiérrez"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfjDv52UhVwu"
      },
      "source": [
        "En este notebook desarrollamos un modelo de clasificación supervisada para predecir el rendimiento global de los estudiantes en las pruebas Saber Pro, utilizando técnicas avanzadas de ingeniería de características y un modelo CatBoost optimizado para datos categóricos. A lo largo del flujo, realizamos el procesamiento del conjunto de entrenamiento, entrenamos el modelo en fase de validación para evaluar su desempeño y finalmente construimos un modelo definitivo con todos los datos disponibles para generar el archivo de envío requerido por Kaggle. Este notebook documenta de manera clara cada paso del proceso para garantizar reproducibilidad, trazabilidad y comprensión del pipeline completo.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpzc75qshfpY"
      },
      "source": [
        "# **1. Extrayendo Información desde Kaggle**\n",
        "\n",
        "En esta sección descargamos los archivos oficiales de la competencia directamente desde Kaggle usando la interfaz de línea de comandos, lo cual nos permite obtener las versiones más recientes del conjunto de entrenamiento, prueba y ejemplos de envío. Esta descarga garantiza que trabajemos con los datos proporcionados por la competencia sin modificaciones locales y mantiene la coherencia entre el entorno de trabajo y la plataforma de evaluación. Además, dejar explícito el comando de extracción permite que cualquier persona que abra el notebook pueda replicar el proceso fácilmente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lO_jkzozuVuI",
        "outputId": "b4045132-e04f-40fc-bd60-7214d8333205"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading udea-ai-4-eng-20252-pruebas-saber-pro-colombia.zip to /content\n",
            "\r  0% 0.00/29.9M [00:00<?, ?B/s]\n",
            "\r100% 29.9M/29.9M [00:00<00:00, 1.22GB/s]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '.'\n",
        "!chmod 600 ./kaggle.json\n",
        "!kaggle competitions download -c udea-ai-4-eng-20252-pruebas-saber-pro-colombia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTOVjC5BuW4o",
        "outputId": "ee63ac14-5cc7-444d-fec4-c1f682c0860e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   296787    296787   4716673 submission_example.csv\n",
            "   296787   4565553  59185238 test.csv\n"
          ]
        }
      ],
      "source": [
        "!unzip udea*.zip > /dev/null\n",
        "!wc *.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqxyGENmgKDt"
      },
      "source": [
        "# **2. Importaciones e instalaciones necesarias**\n",
        "\n",
        "En esta sección instalamos y cargamos todas las librerías esenciales que utilizaremos a lo largo del desarrollo del modelo. Primero instalamos CatBoost, un algoritmo altamente eficiente para manejar grandes cantidades de variables categóricas y adecuado para problemas de clasificación multiclase como el rendimiento Saber Pro. Luego importamos herramientas de manejo de datos como pandas y numpy, junto con funciones de scikit-learn para realizar particiones, métricas de evaluación y manejo de pools de datos. Finalmente, cargamos librerías de visualización como matplotlib y seaborn, que nos permitirán analizar el comportamiento del modelo a través de gráficas como la matriz de confusión y las curvas de aprendizaje. Estas importaciones preparan el entorno completo para ejecutar todo el pipeline de principio a fin.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjgX6MUPBXFk"
      },
      "outputs": [],
      "source": [
        "!pip install catboost\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from catboost import CatBoostClassifier, Pool\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLKcA7gags0O"
      },
      "source": [
        "# **3. Definición de la Clase del Modelo**\n",
        "\n",
        "En esta sección definimos la clase encargada de todo el proceso de construcción del modelo de predicción, incluyendo el preprocesamiento, la ingeniería de características, el entrenamiento y la generación de predicciones finales. Esta clase agrupa de manera modular y organizada todas las funciones necesarias para limpiar los datos, transformar variables categóricas, realizar codificación basada en el rendimiento histórico, crear nuevas características socioeconómicas y educativas, entrenar el modelo CatBoost y producir los resultados en el formato requerido por Kaggle. Centralizar el pipeline dentro de una clase permite mantener el código más limpio, reutilizable y fácil de depurar, además de facilitar la ejecución tanto del modelo de validación como del modelo final entrenado con todos los datos disponibles.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzdcthT2JlB2"
      },
      "outputs": [],
      "source": [
        "class StudentPerformanceClassifier:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.model = None\n",
        "        self.feature_importance = None\n",
        "        self.target_encodings = {}\n",
        "        self.training_columns = []\n",
        "        self.categorical_features = []\n",
        "        self.evals_result = None\n",
        "        self.df_train = None\n",
        "\n",
        "    # -----------------------------------------------------------\n",
        "    # Convertir rendimiento a número\n",
        "    # -----------------------------------------------------------\n",
        "    def rendimiento_to_numeric(self, rendimiento):\n",
        "        mapping = {'bajo': 0, 'medio-bajo': 1, 'medio-alto': 2, 'alto': 3}\n",
        "        return mapping.get(rendimiento)\n",
        "\n",
        "    # -----------------------------------------------------------\n",
        "    # Target encoding: programa y departamento\n",
        "    # -----------------------------------------------------------\n",
        "    def create_location_program_features(self, df, target_df=None):\n",
        "\n",
        "        if target_df is not None:\n",
        "            target_df = target_df.copy()\n",
        "            target_df[\"RENDIMIENTO_NUM\"] = target_df[\"RENDIMIENTO_GLOBAL\"].map(self.rendimiento_to_numeric)\n",
        "\n",
        "            prog_stats = target_df.groupby(\"E_PRGM_ACADEMICO\")[\"RENDIMIENTO_NUM\"].agg([\"mean\", \"std\", \"size\"])\n",
        "            prog_stats.columns = [\"PROG_RENDIMIENTO_MEDIO\", \"PROG_RENDIMIENTO_STD\", \"PROG_COUNT\"]\n",
        "\n",
        "            dept_stats = target_df.groupby(\"E_PRGM_DEPARTAMENTO\")[\"RENDIMIENTO_NUM\"].agg([\"mean\", \"std\", \"size\"])\n",
        "            dept_stats.columns = [\"DEPT_RENDIMIENTO_MEDIO\", \"DEPT_RENDIMIENTO_STD\", \"DEPT_COUNT\"]\n",
        "\n",
        "            self.target_encodings[\"programa\"] = prog_stats\n",
        "            self.target_encodings[\"departamento\"] = dept_stats\n",
        "\n",
        "        # Merge programa\n",
        "        if \"programa\" in self.target_encodings:\n",
        "            df = df.merge(self.target_encodings[\"programa\"], how=\"left\", on=\"E_PRGM_ACADEMICO\")\n",
        "\n",
        "        # Merge departamento\n",
        "        if \"departamento\" in self.target_encodings:\n",
        "            df = df.merge(self.target_encodings[\"departamento\"], how=\"left\", on=\"E_PRGM_DEPARTAMENTO\")\n",
        "\n",
        "        df[[\"PROG_RENDIMIENTO_MEDIO\", \"PROG_RENDIMIENTO_STD\", \"PROG_COUNT\"]] = \\\n",
        "            df[[\"PROG_RENDIMIENTO_MEDIO\", \"PROG_RENDIMIENTO_STD\", \"PROG_COUNT\"]].fillna(0)\n",
        "\n",
        "        df[[\"DEPT_RENDIMIENTO_MEDIO\", \"DEPT_RENDIMIENTO_STD\", \"DEPT_COUNT\"]] = \\\n",
        "            df[[\"DEPT_RENDIMIENTO_MEDIO\", \"DEPT_RENDIMIENTO_STD\", \"DEPT_COUNT\"]].fillna(0)\n",
        "\n",
        "        return df\n",
        "\n",
        "    # -----------------------------------------------------------\n",
        "    # Features educativas\n",
        "    # -----------------------------------------------------------\n",
        "    def create_education_features(self, df):\n",
        "\n",
        "        mapping = {\n",
        "            'Ninguno': 0,\n",
        "            'Primaria incompleta': 1,\n",
        "            'Primaria completa': 2,\n",
        "            'Secundaria (Bachillerato) incompleta': 3,\n",
        "            'Secundaria (Bachillerato) completa': 4,\n",
        "            'Técnica o tecnológica incompleta': 5,\n",
        "            'Técnica o tecnológica completa': 6,\n",
        "            'Educación profesional incompleta': 7,\n",
        "            'Educación profesional completa': 8,\n",
        "            'Postgrado': 9,\n",
        "            'No reporta': 4\n",
        "        }\n",
        "\n",
        "        df[\"FAMI_EDUCACIONPADRE_NUM\"] = df[\"F_EDUCACIONPADRE\"].map(mapping)\n",
        "        df[\"FAMI_EDUCACIONMADRE_NUM\"] = df[\"F_EDUCACIONMADRE\"].map(mapping)\n",
        "\n",
        "        df[\"FAMI_EDUCACION_PROMEDIO\"] = (\n",
        "            df[\"FAMI_EDUCACIONPADRE_NUM\"] + df[\"FAMI_EDUCACIONMADRE_NUM\"]\n",
        "        ) / 2\n",
        "\n",
        "        df[\"FAMI_EDUCACION_DIFERENCIA\"] = abs(\n",
        "            df[\"FAMI_EDUCACIONPADRE_NUM\"] - df[\"FAMI_EDUCACIONMADRE_NUM\"]\n",
        "        )\n",
        "\n",
        "        df[\"FAMI_EDUCACION_MAX\"] = df[[\"FAMI_EDUCACIONPADRE_NUM\", \"FAMI_EDUCACIONMADRE_NUM\"]].max(axis=1)\n",
        "        df[\"FAMI_EDUCACION_MIN\"] = df[[\"FAMI_EDUCACIONPADRE_NUM\", \"FAMI_EDUCACIONMADRE_NUM\"]].min(axis=1)\n",
        "\n",
        "        return df\n",
        "\n",
        "    # -----------------------------------------------------------\n",
        "    # Features económicas según dataset REAL\n",
        "    # -----------------------------------------------------------\n",
        "    def create_economic_features(self, df):\n",
        "\n",
        "        estrato_mapping = {\n",
        "            \"1\": 1, \"2\": 2, \"3\": 3, \"4\": 4, \"5\": 5, \"6\": 6,\n",
        "            \"No reporta\": 3\n",
        "        }\n",
        "\n",
        "        matricula_mapping = {\n",
        "            'Menos de 500 mil': 0,\n",
        "            'Entre 500 mil y menos de 1 millón': 1,\n",
        "            'Entre 1 millón y menos de 2.5 millones': 2,\n",
        "            'Entre 2.5 millones y menos de 4 millones': 3,\n",
        "            'Entre 4 millones y menos de 5.5 millones': 4,\n",
        "            'Entre 5.5 millones y menos de 7 millones': 5,\n",
        "            'Más de 7 millones': 6,\n",
        "            'No reporta': 3\n",
        "        }\n",
        "\n",
        "        df[\"FAMI_ESTRATO_NUM\"] = df[\"F_ESTRATOVIVIENDA\"].map(estrato_mapping)\n",
        "        df[\"MATRICULA_NUM\"] = df[\"E_VALORMATRICULAUNIVERSIDAD\"].map(matricula_mapping)\n",
        "\n",
        "        df[\"INTERNET_BIN\"] = (df[\"F_TIENEINTERNET\"] == \"Si\").astype(int)\n",
        "\n",
        "        df[\"SCORE_SOCIOECONOMICO\"] = (\n",
        "            df[\"FAMI_ESTRATO_NUM\"] * 0.4\n",
        "            + df[\"MATRICULA_NUM\"] * 0.4\n",
        "            + df[\"INTERNET_BIN\"] * 0.2\n",
        "        )\n",
        "\n",
        "        return df\n",
        "\n",
        "    # -----------------------------------------------------------\n",
        "    # Preprocesamiento común\n",
        "    # -----------------------------------------------------------\n",
        "    def _preprocess_common(self, df):\n",
        "\n",
        "        cols_to_drop = [\n",
        "            \"ID\",\n",
        "            \"INDICADOR_1\",\n",
        "            \"INDICADOR_2\",\n",
        "            \"INDICADOR_3\",\n",
        "            \"INDICADOR_4\",\n",
        "            \"F_TIENEINTERNET.1\"\n",
        "        ]\n",
        "\n",
        "        X = df.drop(columns=[c for c in cols_to_drop if c in df.columns], errors=\"ignore\").copy()\n",
        "\n",
        "        y = None\n",
        "        if \"RENDIMIENTO_GLOBAL\" in X.columns:\n",
        "            y = X.pop(\"RENDIMIENTO_GLOBAL\")\n",
        "\n",
        "        # Rellenar NaNs de categóricas\n",
        "        for col in X.select_dtypes(include=[\"object\"]).columns:\n",
        "            X[col] = X[col].fillna(\"No reporta\")\n",
        "\n",
        "        # Convertir periodo a string\n",
        "        if \"PERIODO_ACADEMICO\" in X.columns:\n",
        "            X[\"PERIODO_ACADEMICO\"] = X[\"PERIODO_ACADEMICO\"].astype(str)\n",
        "\n",
        "        X = self.create_education_features(X)\n",
        "        X = self.create_economic_features(X)\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    # -----------------------------------------------------------\n",
        "    # Preprocesamiento completo\n",
        "    # -----------------------------------------------------------\n",
        "    def preprocess_data(self, data, validation_mode=True):\n",
        "\n",
        "        X, y = self._preprocess_common(data)\n",
        "\n",
        "        if validation_mode:\n",
        "\n",
        "            print(\"Modo: Validación (dividiendo datos)\")\n",
        "\n",
        "            X_train, X_test, y_train, y_test = train_test_split(\n",
        "                X, y, test_size=0.2, random_state=42, stratify=y\n",
        "            )\n",
        "\n",
        "            train_target_df = X_train.copy()\n",
        "            train_target_df[\"RENDIMIENTO_GLOBAL\"] = y_train\n",
        "\n",
        "            X_train = self.create_location_program_features(X_train, train_target_df)\n",
        "            X_test = self.create_location_program_features(X_test)\n",
        "\n",
        "            self.df_train = X_train.copy()\n",
        "            self.training_columns = X_train.columns\n",
        "            self.categorical_features = X_train.select_dtypes(include=[\"object\"]).columns.tolist()\n",
        "\n",
        "            return (\n",
        "                Pool(X_train, y_train, cat_features=self.categorical_features),\n",
        "                Pool(X_test, y_test, cat_features=self.categorical_features)\n",
        "            )\n",
        "\n",
        "        else:\n",
        "            print(\"Modo: Entrenamiento final\")\n",
        "\n",
        "            df_target = pd.concat([X, y.rename(\"RENDIMIENTO_GLOBAL\")], axis=1)\n",
        "            X = self.create_location_program_features(X, df_target)\n",
        "\n",
        "            self.df_train = X.copy()\n",
        "            self.training_columns = X.columns\n",
        "            self.categorical_features = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
        "\n",
        "            return Pool(X, y, cat_features=self.categorical_features)\n",
        "\n",
        "    # -----------------------------------------------------------\n",
        "    # Entrenamiento\n",
        "    # -----------------------------------------------------------\n",
        "    def train_model(self, train_pool, eval_pool=None):\n",
        "\n",
        "        self.model = CatBoostClassifier(\n",
        "            iterations=3000,\n",
        "            loss_function='MultiClass',\n",
        "            eval_metric='Accuracy',\n",
        "            random_seed=42,\n",
        "            task_type='GPU',\n",
        "            verbose=100,\n",
        "            early_stopping_rounds=50,\n",
        "            learning_rate=0.03322175851979197,\n",
        "            depth=8,\n",
        "            l2_leaf_reg=10.46509730642616,\n",
        "            bootstrap_type='Bayesian',\n",
        "            bagging_temperature=0.4868502171372011,\n",
        "            one_hot_max_size=10,\n",
        "            leaf_estimation_method='Newton'\n",
        "        )\n",
        "\n",
        "        self.model.fit(\n",
        "            train_pool,\n",
        "            eval_set=eval_pool,\n",
        "            use_best_model=bool(eval_pool)\n",
        "        )\n",
        "\n",
        "        if eval_pool is not None:\n",
        "            self.evals_result = self.model.get_evals_result()\n",
        "\n",
        "        self.feature_importance = self.model.get_feature_importance(train_pool)\n",
        "\n",
        "    def plot_learning_curve(self):\n",
        "\n",
        "        if self.evals_result is None:\n",
        "            print(\"No hay resultados de evaluación. Entrena con validation_mode=True.\")\n",
        "            return\n",
        "\n",
        "        results = self.evals_result\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "        # Accuracy\n",
        "        ax1.plot(results['learn']['Accuracy'], label='Train Accuracy')\n",
        "        ax1.plot(results['validation']['Accuracy'], label='Validation Accuracy')\n",
        "        ax1.legend()\n",
        "        ax1.set_title('Accuracy Curve')\n",
        "        ax1.set_xlabel('Iterations')\n",
        "\n",
        "        # Loss\n",
        "        ax2.plot(results['learn']['MultiClass'], label='Train Loss')\n",
        "        ax2.plot(results['validation']['MultiClass'], label='Validation Loss')\n",
        "        ax2.legend()\n",
        "        ax2.set_title('Loss Curve')\n",
        "        ax2.set_xlabel('Iterations')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    # -----------------------------------------------------------\n",
        "    # Evaluación\n",
        "    # -----------------------------------------------------------\n",
        "    def evaluate_model(self, test_pool):\n",
        "\n",
        "        if self.model is None:\n",
        "            print(\"El modelo no ha sido entrenado.\")\n",
        "            return None, None\n",
        "\n",
        "        predictions = self.model.predict(test_pool)\n",
        "        y_true = test_pool.get_label()\n",
        "\n",
        "        report = classification_report(y_true, predictions, target_names=self.model.classes_)\n",
        "        cm = confusion_matrix(y_true, predictions, labels=self.model.classes_)\n",
        "\n",
        "        return report, cm\n",
        "\n",
        "    # -----------------------------------------------------------\n",
        "    # Predicción final\n",
        "    # -----------------------------------------------------------\n",
        "    def predict(self, X_test_df):\n",
        "\n",
        "        if self.model is None:\n",
        "            raise ValueError(\"El modelo debe ser entrenado primero.\")\n",
        "\n",
        "        X_test, _ = self._preprocess_common(X_test_df)\n",
        "        X_test = self.create_location_program_features(X_test)\n",
        "\n",
        "        X_test = X_test.reindex(columns=self.training_columns, fill_value=0)\n",
        "\n",
        "        return self.model.predict(X_test)\n",
        "\n",
        "    # -----------------------------------------------------------\n",
        "    # Guardar submission\n",
        "    # -----------------------------------------------------------\n",
        "    def save_predictions(self, X_test_df, filename):\n",
        "\n",
        "        preds = self.predict(X_test_df)\n",
        "\n",
        "        df = pd.DataFrame({\n",
        "            \"ID\": X_test_df[\"ID\"],\n",
        "            \"RENDIMIENTO_GLOBAL\": preds.flatten()\n",
        "        })\n",
        "\n",
        "        df.to_csv(filename, index=False)\n",
        "        print(f\"Archivo guardado como {filename}\")\n",
        "\n",
        "        return df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmwk43uahNL_"
      },
      "source": [
        "# **4. Uso de la Clase**\n",
        "\n",
        "En esta sección utilizamos la clase previamente definida para ejecutar el flujo completo de validación del modelo, comenzando por cargar el dataset de entrenamiento, aplicar todo el proceso de preprocesamiento y generar los conjuntos de datos internos que CatBoost requiere (train_pool y test_pool). Luego se instancia el clasificador, se divide la información en datos de entrenamiento y validación y se entrena el modelo activando técnicas como early stopping gracias al uso del eval_pool. Este paso nos permite verificar el comportamiento real del modelo antes de entrenar la versión final, analizar su rendimiento, revisar las curvas de aprendizaje y validar que todos los componentes del pipeline —como la ingeniería de características, las codificaciones y los parámetros del modelo— están funcionando correctamente antes de continuar con el entrenamiento final y la creación del archivo de envío para Kaggle.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZkPk0SB-dPI"
      },
      "outputs": [],
      "source": [
        "# Cargar datos\n",
        "data = pd.read_csv('train.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPv5aCJyurXQ"
      },
      "outputs": [],
      "source": [
        "# Instanciar el clasificador\n",
        "print(\"=== Iniciando Fase de Validación ===\")\n",
        "classifier = StudentPerformanceClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jb2osikG3TUr"
      },
      "outputs": [],
      "source": [
        "# Preprocesamiento en modo validación\n",
        "train_pool, test_pool = classifier.preprocess_data(\n",
        "    data,\n",
        "    validation_mode=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urOiLanC3VLf"
      },
      "outputs": [],
      "source": [
        "# Entrenamiento del modelo con eval_pool para activar early stopping\n",
        "print(\"\\n=== Entrenando modelo de validación... ===\")\n",
        "classifier.train_model(train_pool, eval_pool=test_pool)\n",
        "print(\"=== Entrenamiento completado ===\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OcmC_s-y5n9m"
      },
      "outputs": [],
      "source": [
        "# Graficar curvas de aprendizaje\n",
        "print(\"\\n=== Curvas de aprendizaje ===\")\n",
        "classifier.plot_learning_curve()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJC_pfVmihwh"
      },
      "outputs": [],
      "source": [
        "# Ver la forma final de los datos preprocesados\n",
        "classifier.df_train.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVfmJ9fGhb7f"
      },
      "source": [
        "# **5. Evaluación del Modelo en Fase de Validación**\n",
        "\n",
        "En esta sección evaluamos el rendimiento del modelo entrenado durante la fase de validación, utilizando exclusivamente el conjunto de datos reservado como test interno para medir la capacidad real de generalización. A partir de las predicciones generadas por el modelo, calculamos métricas clave como precisión, recall, f1-score y accuracy, lo que nos permite identificar el comportamiento del clasificador en cada una de las clases objetivo del rendimiento académico. Asimismo, construimos y visualizamos la matriz de confusión para detectar patrones de error, especialmente la forma en que el modelo distingue entre categorías como medio-alto y medio-bajo, que suelen presentar mayor confusión. Esta evaluación es fundamental para validar que la ingeniería de características, las codificaciones y los parámetros del modelo están funcionando correctamente antes de proceder al entrenamiento final con todos los datos disponibles.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8ADL8GdheVH"
      },
      "outputs": [],
      "source": [
        "report, cm = classifier.evaluate_model(test_pool)\n",
        "\n",
        "# Nombres reales de las clases\n",
        "label_names = ['bajo', 'medio-bajo', 'medio-alto', 'alto']\n",
        "\n",
        "print(\"\\n=== Reporte de Clasificación ===\")\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=== Matriz de Confusión ===\")\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "sns.heatmap(\n",
        "    cm,\n",
        "    annot=True,\n",
        "    fmt=\"d\",\n",
        "    cmap=\"Blues\",\n",
        "    xticklabels=label_names,\n",
        "    yticklabels=label_names\n",
        ")\n",
        "\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "H1qgAB2L4n6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPB1Y5H9hg2X"
      },
      "source": [
        "# **6. Entrenamiento Final y Generación de Predicciones para Kaggle**\n",
        "\n",
        "En esta etapa realizamos el entrenamiento final del modelo utilizando el 100% de los datos disponibles en el archivo *train.csv*, sin dividir en validación, con el fin de maximizar la capacidad de aprendizaje del clasificador antes de generar las predicciones oficiales para el reto de Kaggle. Primero se preprocesa nuevamente todo el dataset completo, aplicando la misma ingeniería de características, codificaciones y transformaciones que se emplearon en la fase de validación, garantizando consistencia entre el modelo final y las pruebas anteriores. Una vez entrenado el modelo final, cargamos el archivo *test.csv*, aplicamos el preprocesamiento correspondiente y generamos las etiquetas de rendimiento para cada estudiante, produciendo finalmente el archivo *my_submission.csv* en el formato exacto exigido por la plataforma. Este archivo será el que posteriormente se enviará a Kaggle para obtener la puntuación del modelo en los datos ocultos del concurso."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBf7ZC2T3vqT"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\\n--- Iniciando Fase de Entrenamiento Final ---\")\n",
        "\n",
        "# Cargar test de Kaggle\n",
        "X_test = pd.read_csv('test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear nuevo clasificador limpio\n",
        "final_classifier = StudentPerformanceClassifier()"
      ],
      "metadata": {
        "id": "CJfAwJo34zyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocesar TODOS los datos de entrenamiento (sin validación)\n",
        "final_train_pool = final_classifier.preprocess_data(\n",
        "    data,\n",
        "    validation_mode=False\n",
        ")"
      ],
      "metadata": {
        "id": "Sa5eDzVZ41bb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenar el modelo final\n",
        "print(\"\\n--- Entrenando modelo final... ---\")\n",
        "final_classifier.train_model(final_train_pool)\n",
        "print(\"--- Entrenamiento final completado. ---\")"
      ],
      "metadata": {
        "id": "zpcC1ymw42x9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Tq5XA7oKGHv"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# GENERAR Y GUARDAR PREDICCIONES PARA KAGGLE\n",
        "# ============================================================\n",
        "\n",
        "results = final_classifier.save_predictions(\n",
        "    X_test,\n",
        "    'my_submission.csv'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission = final_classifier.save_predictions(X_test, \"my_submission.csv\")\n",
        "submission.head()\n"
      ],
      "metadata": {
        "id": "Ow5PmoCZJ2ma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSSEaMugNoQU"
      },
      "outputs": [],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bc672780"
      },
      "outputs": [],
      "source": [
        "print(\"\\n=== Conteo de clases reales (train) ===\")\n",
        "print(data['RENDIMIENTO_GLOBAL'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27wJajj3hngv"
      },
      "source": [
        "# **7. Envío del archivo a Kaggle**\n",
        "\n",
        "En esta sección realizamos el envío oficial del archivo *my_submission.csv* a Kaggle. Una vez entrenado el modelo final y generadas las predicciones, usamos la interfaz de línea de comandos de Kaggle para cargar el archivo en la competencia y obtener la puntuación correspondiente en los datos ocultos del reto. Este paso completa el pipeline, permitiendo evaluar el desempeño real del modelo en el entorno competitivo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpRe_3ikf_eU"
      },
      "outputs": [],
      "source": [
        "!head my_submission.csv\n",
        "!kaggle competitions list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CaIRv8EvgDjv"
      },
      "outputs": [],
      "source": [
        "!kaggle competitions submit -c udea-ai-4-eng-20252-pruebas-saber-pro-colombia -f my_submission.csv -m \"versión final catboost\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}